{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "all_tracks = pickle.load(open('all_tracks.pkl', 'rb'))\n",
    "raag = pickle.load(open('raag.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encode Raags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(raag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Asa', 'Asa Kafi', 'Asavari', 'Bairarri', 'Basant', 'Dhanasri'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 5, 5, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = le.transform(raag)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change it back\n",
    "#le.inverse_transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(all_tracks), \n",
    "                                                    np.array(y),\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, \n",
    "                                                y_test,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, output_layers):\n",
    "    \n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten the output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    # output layer \n",
    "    model.add(keras.layers.Dense(output_layers, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4543, 128, 196, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = build_model(input_shape, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "142/142 [==============================] - 81s 562ms/step - loss: 1.4645 - accuracy: 0.4658 - val_loss: 1.3423 - val_accuracy: 0.4665\n",
      "Epoch 2/30\n",
      "142/142 [==============================] - 75s 524ms/step - loss: 1.1323 - accuracy: 0.5661 - val_loss: 1.1883 - val_accuracy: 0.5594\n",
      "Epoch 3/30\n",
      "142/142 [==============================] - 71s 503ms/step - loss: 0.9609 - accuracy: 0.6381 - val_loss: 1.1729 - val_accuracy: 0.5416\n",
      "Epoch 4/30\n",
      "142/142 [==============================] - 75s 529ms/step - loss: 0.8004 - accuracy: 0.7050 - val_loss: 0.9781 - val_accuracy: 0.6309\n",
      "Epoch 5/30\n",
      "142/142 [==============================] - 76s 536ms/step - loss: 0.6660 - accuracy: 0.7587 - val_loss: 0.9213 - val_accuracy: 0.6399\n",
      "Epoch 6/30\n",
      "142/142 [==============================] - 75s 530ms/step - loss: 0.5565 - accuracy: 0.8034 - val_loss: 0.7784 - val_accuracy: 0.7230\n",
      "Epoch 7/30\n",
      "142/142 [==============================] - 78s 549ms/step - loss: 0.4836 - accuracy: 0.8369 - val_loss: 0.6441 - val_accuracy: 0.7730\n",
      "Epoch 8/30\n",
      "142/142 [==============================] - 74s 522ms/step - loss: 0.4263 - accuracy: 0.8569 - val_loss: 0.6776 - val_accuracy: 0.7641\n",
      "Epoch 9/30\n",
      "142/142 [==============================] - 76s 536ms/step - loss: 0.3740 - accuracy: 0.8783 - val_loss: 0.6825 - val_accuracy: 0.7587\n",
      "Epoch 10/30\n",
      "142/142 [==============================] - 73s 513ms/step - loss: 0.3213 - accuracy: 0.8974 - val_loss: 0.5793 - val_accuracy: 0.7989\n",
      "Epoch 11/30\n",
      "142/142 [==============================] - 78s 549ms/step - loss: 0.2904 - accuracy: 0.9014 - val_loss: 0.5352 - val_accuracy: 0.8213\n",
      "Epoch 12/30\n",
      "142/142 [==============================] - 79s 558ms/step - loss: 0.2666 - accuracy: 0.9164 - val_loss: 0.5203 - val_accuracy: 0.8132\n",
      "Epoch 13/30\n",
      "142/142 [==============================] - 78s 547ms/step - loss: 0.2251 - accuracy: 0.9287 - val_loss: 0.4724 - val_accuracy: 0.8481\n",
      "Epoch 14/30\n",
      "142/142 [==============================] - 85s 601ms/step - loss: 0.2100 - accuracy: 0.9340 - val_loss: 0.4992 - val_accuracy: 0.8436\n",
      "Epoch 15/30\n",
      "142/142 [==============================] - 79s 555ms/step - loss: 0.1932 - accuracy: 0.9386 - val_loss: 0.4973 - val_accuracy: 0.8168\n",
      "Epoch 16/30\n",
      "142/142 [==============================] - 80s 561ms/step - loss: 0.1708 - accuracy: 0.9459 - val_loss: 0.4151 - val_accuracy: 0.8552\n",
      "Epoch 17/30\n",
      "142/142 [==============================] - 78s 551ms/step - loss: 0.1601 - accuracy: 0.9529 - val_loss: 0.4550 - val_accuracy: 0.8463\n",
      "Epoch 18/30\n",
      "142/142 [==============================] - 76s 539ms/step - loss: 0.1529 - accuracy: 0.9538 - val_loss: 0.4581 - val_accuracy: 0.8409\n",
      "Epoch 19/30\n",
      "142/142 [==============================] - 78s 548ms/step - loss: 0.1368 - accuracy: 0.9586 - val_loss: 0.4460 - val_accuracy: 0.8490\n",
      "Epoch 20/30\n",
      "142/142 [==============================] - 77s 544ms/step - loss: 0.1220 - accuracy: 0.9643 - val_loss: 0.3814 - val_accuracy: 0.8794\n",
      "Epoch 21/30\n",
      "142/142 [==============================] - 76s 534ms/step - loss: 0.1159 - accuracy: 0.9663 - val_loss: 0.4152 - val_accuracy: 0.8749\n",
      "Epoch 22/30\n",
      "142/142 [==============================] - 80s 564ms/step - loss: 0.1101 - accuracy: 0.9683 - val_loss: 0.3726 - val_accuracy: 0.8811\n",
      "Epoch 23/30\n",
      "142/142 [==============================] - 74s 525ms/step - loss: 0.0981 - accuracy: 0.9698 - val_loss: 0.3776 - val_accuracy: 0.8829\n",
      "Epoch 24/30\n",
      "142/142 [==============================] - 75s 530ms/step - loss: 0.0936 - accuracy: 0.9740 - val_loss: 0.3745 - val_accuracy: 0.8767\n",
      "Epoch 25/30\n",
      "142/142 [==============================] - 76s 533ms/step - loss: 0.0930 - accuracy: 0.9696 - val_loss: 0.3763 - val_accuracy: 0.8740\n",
      "Epoch 26/30\n",
      "142/142 [==============================] - 71s 501ms/step - loss: 0.0841 - accuracy: 0.9736 - val_loss: 0.3766 - val_accuracy: 0.8785\n",
      "Epoch 27/30\n",
      "142/142 [==============================] - 75s 531ms/step - loss: 0.0751 - accuracy: 0.9771 - val_loss: 0.3813 - val_accuracy: 0.8794\n",
      "Epoch 28/30\n",
      "142/142 [==============================] - 78s 552ms/step - loss: 0.0791 - accuracy: 0.9773 - val_loss: 0.3587 - val_accuracy: 0.8740\n",
      "Epoch 29/30\n",
      "142/142 [==============================] - 75s 530ms/step - loss: 0.0745 - accuracy: 0.9771 - val_loss: 0.3295 - val_accuracy: 0.8856\n",
      "Epoch 30/30\n",
      "142/142 [==============================] - 80s 566ms/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 0.3561 - val_accuracy: 0.8847\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=32,\n",
    "                    epochs=30) # refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 3s 75ms/step - loss: 0.3568 - accuracy: 0.8874\n",
      "Test set accuracy: 0.887399435043335\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test set accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "\n",
    "    X = X[np.newaxis, ...] # make into a 4d array\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    # extract index with max value (most likely raag)\n",
    "    prediced_index = np.argmax(prediction, axis=1) # returns a 1d array\n",
    "    print(\"Expected index: {}, Predicted index {}\".format(y, prediced_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on a sample\n",
    "X_pred = X_test[77]\n",
    "y_pred = y_test[77]\n",
    "\n",
    "predict(model, X_pred, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raag_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5074d931aa31016af7b8019b82a8ef3b52424e57a6239786ead2301e92867089"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
